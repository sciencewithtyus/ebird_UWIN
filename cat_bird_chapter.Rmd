---
title: "Mapping_Visuals"
author: "Tyus D. Williams, Diego-Ellis Soto, Cesar O. Estien, and Christopher J. Schell"
date: "1/22/2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
here::i_am("cat_bird_chapter.Rmd")
here()  # this establishes what the path to the current file is relative to project foot
```

## Install pckgs here

```{r install necessary packages for analysis}
install.packages(c("cowplot", "googleway", "ggplot2", "ggrepel", 
"ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata", type = 'source'))

# install the github version of ggmap
devtools::install_github("dkahle/ggmap")

# now we have to load up the libraries for what we want
library(ggplot2)
library(ggmap)
library(maps)
library(mapdata)
```

Now our packages are loaded into our work space which is great!

## State Map Visuals ##
```{r Building State Maps }
# now we can manipulate some dfs to create boundaries for states

states <- map_data("state") # we can now create a new df for the states we want to observe
dim(states)
head(states)
tail(states)

# plot all the states, all colored differently
ggplot(data = states) +
  geom_polygon(aes(x=long, y=lat, fill = region, group = group), color = "white") +
  coord_fixed(1.3) +
  guides(fill=FALSE) # do this to leave off the color legend

 # now we can plot a subset of states we are interested in for our interest
west_coast <- subset(states, region %in% c("california", "oregon", "washington"))
ggplot(data = west_coast) +
  geom_polygon(aes(x=long, y=lat), fill = "palegreen", color = "black") # this is ugly we need to include the groups and coords

# here is the correct version we should be using
ggplot(data = west_coast) +
  geom_polygon(aes(x=long, y = lat, group = group), fill = "lightblue", color = "black") +
  coord_fixed(1.3)
```
## Visualizing California ##
```{r displaying county lines in california and data}
library(sf)
library(cowplot)
library(rcartocolor)
library(spData)
theme_set(theme_bw()) # set a theme for the maps

ca_df <- subset(states, region == "california") # this will give us the entirety of the state details
head(ca_df)

# now we need the county lines of interest
counties <- map_data("county")
ca_county <- subset(counties, region == "california")
eastbay_counties <- subset(counties, subregion == c("alameda", "contra costa"))
tail(eastbay_counties)

# now we plot the state without the grid lines and background
 ca_base <- ggplot(data = ca_df, mapping = aes(x=long, y=lat, group=group)) +
  geom_polygon(color = "black", fill = "grey") +
   coord_fixed(1.3)
 
 ca_base + geom_polygon(data = ca_county, fill = NA, color = "white") +
   geom_polygon(color = "black", fill = NA ) +
  theme_void() # this gives us a clear map of california
  
# now plot the county boundaries in white with east bay in red lines
  ca_base2 <- ca_base +
    geom_polygon(data = ca_county, fill = NA, color = "white") +
    geom_polygon(data = eastbay_counties, fill = NA, color = "red4") +
    geom_polygon(color = "black", fill = NA) +
    coord_fixed(1.3)  # get the state border back on top
  
  # now lets zoom into the east bay
  ca_base2 + coord_fixed(xlim = c(-123.5, -121.0), ylim = c(36.7, 38.8), ratio = 1.3)
  
  #### Now we can make an inset map for California and my study area ####
  cam.stations = read.csv("~/Desktop/Meso_Study/general_data/Camera_Station_Table.csv")
  cali_sf = read_sf("~/Desktop/Meso_Study/eb_shapefiles/ca_state/CA_State.shp")
  counties_sf = read_sf("~/Desktop/Meso_Study/eb_shapefiles/ca_counties2/CA_Counties.shp")
  ca_places = read_sf("~/Desktop/Meso_Study/eb_shapefiles/ca_places/CA_Places.shp")

  plot(st_geometry(cali_sf), col = "darkblue",
       main = "California State", axes = TRUE) # okay the sf state file works which is great
  st_crs(ca_places)==st_crs(counties_sf) # coordinate systems are the same
  eb_outline = st_transform(eb_outline, crs = st_crs(cali_sf)) # set the correct crs for the eb_outline
  
  # now we need to join the places and eb_outline shapefiles
  ca_places_filtered <- st_join(ca_places, counties_sf, join = st_within, left = FALSE)
  ca_places_filtered <- ca_places_filtered %>% 
    filter(NAMELSAD.y %in% c("Contra Costa County", "Alameda County"))
  
  # now we convert the gps points to sf features and add to the map
  shoreline_sf <- Deployments %>% dplyr::select(deployment_id, placename, latitude, longitude)
  shoreline_sf <- st_as_sf(shoreline_sf, coords = c("longitude", "latitude"),
                       crs = st_crs(eb_outline)) # this looks good
  cam.stations <- st_as_sf(cam.stations, coords = c("utm_x", "utm_y"), crs = st_crs(cali_sf))
  
  bbox <- st_bbox(eb_outline) # extract the bounding box of the eb_outline
  bbox_polygon <- st_as_sfc(bbox)
  st_geometry_type(shoreline_sf)
  if(st_crs(shoreline_sf) != st_crs(eb_outline)) {
    shoreline_sf <- st_transform(shoreline_sf, crs = st_crs(cali_sf))
  }
  # Verify the transformation
    print(st_crs(shoreline_sf))
    print(st_crs(eb_outline))
    print(st_bbox(shoreline_sf))
    print(st_bbox(eb_outline))
  # perform spatial intersection of the polygon and sf data
  shoreline_sf_filtered <- st_intersection(shoreline_sf, bbox_polygon)
  
  # remove empty geometries if needed
  shoreline_sf <- shoreline_sf[!st_is_empty(shoreline_sf), ]
  eb_outline <- eb_outline[!st_is_empty(eb_outline), ]
  
  # now we need to add in the counties and highlight them and creat the inset map for my study area
  ebinset1 = ggplot() + 
    geom_sf(data = cali_sf, color = NA, lwd = 0.5, fill = "lightgray") +
    geom_sf(data = counties_sf, color = "black", lwd = 0.5, fill = NA) +
    geom_sf(data = eb_outline, color = "red", lwd = 0.4 , fill = NA) +
    theme_map() +
    theme(panel.background = element_rect(fill = NULL))
  
  # plot the eb outline first
  ggplot() +
    geom_sf(data = eb_outline, fill = "lightgray", color = "black") +
    theme_void() +
    ggtitle("East Bay Outline")
  
  # plot the camera points next
  ggplot() +
    geom_sf(data = shoreline_sf, fill = NA, color = "red3") +
    theme_void() +
    ggtitle("Shoreline Points")
  
    # Simplify geometries if they are very complex
shoreline_sf_simplified <- st_simplify(shoreline_sf, dTolerance = 0.001)
eb_outline_simplified <- st_simplify(eb_outline, dTolerance = 0.001)

# Plot using base R
plot(st_geometry(eb_outline_simplified), col = "lightgray", main = "East Bay Outline with Shoreline Points")
plot(st_geometry(shoreline_sf_simplified), col = "red", add = TRUE) 

# Plot using ggplot2
shoreline_cams <- st_transform(shoreline_sf, st_crs(uwin_outline)) # set the right crs

  ggplot() +
  geom_sf(data = uwin_outline, fill = "lightgray", color = "black") +
  geom_sf(data = shoreline_sf, color = "royalblue", size = 2) +
  theme_minimal() +
  ggtitle("Shoreline Points on East Bay Outline")
  
  ggplot() +
  geom_sf(data = uwin_outline, fill = "lightgray", color = "black") +
  geom_sf(data = shoreline_cams, color = "royalblue", size = 2) +
  coord_sf(xlim = c(min(st_bbox(uwin_outline)[1], st_bbox(shoreline_sf)[1]), 
                    max(st_bbox(uwin_outline)[3], st_bbox(shoreline_sf)[3])), 
           ylim = c(min(st_bbox(uwin_outline)[2], st_bbox(shoreline_sf)[2]), 
                    max(st_bbox(uwin_outline)[4], st_bbox(shoreline_sf)[4])), 
           expand = FALSE) + 
  theme_void() +
  ggtitle("Shoreline Points on East Bay Outline")


    # add the camera gps points into the map! make sure to convert to sf format
  
  # now we need to join the two maps together
   finalinset <-  ggdraw() +
    draw_plot(ebinset2) +
    draw_plot(ebinset1, x = 0.00, y = 0.05, width = 0.37, height = 0.37)
   
   ggsave("finalinset.png", finalinset, width = 8, height = 8)
   
   #### make shapefiles for eb_outline and the camera_stations ####
st_write(shoreline_sf, "output_camerasfile.shp")
st_write(eb_outline, "output_eb_outline.shp")
st_write(cam.stations,"cam_stations.shp") # this should be correct
    
    #map tasks to complete for today Monday 22, 2024#
    # create simple version of map with gps points of camera sites
    # create text labels for each shoreline park location, alternate the colors for the site/camera
    # use letters for each site and then place in a legend
    # insert compass and scale bar for the map
    # map is complete
```

## Make GGMap of Study Area ##
```{r making map visual of the study area using google map process}
# compute the bounding box in ggmap
eb_bbox <- make_bbox(lat = Latitude, lon = Longitude, data = Meso_Data)
eb_bbox

# now we grab the map from google
API_KEY <- "AIzaSyDgv7tb_2B3G6F13QprsC4t5XEegGuJdbc"
ggmap::register_google(key = API_KEY)
eb_big <- ggmap::get_map(location = eb_bbox, source = "google", maptype = "terrain") # bounding box has been given now

# plot the points now for the eb_box details
eb_map <- ggmap(eb_big) +
  geom_point(data =  Meso_Data, mapping = aes(x= Longitude, y = Latitude, color= Sampling.Zone))  # we have a map now!
 print(eb_map + ggtitle("East Bay Regional Shoreline Sampling Zones"))

```

## Making the UWIN GGMAP Visual of all sites ##
```{r integrating the UWIN sites into ggmap and terra mapping}
# first we need to load in the data concerning the UWIN file, adjust the file RxJ!
uwin_sites <- read.csv('~/Desktop/Meso_Study/chapter2datafiles/MSTR_UWIN_sites.csv')
write.csv(uwin_sites, file = '~/Desktop/Meso_Study/chapter2datafiles/MSTR_UWIN_sites.csv')
# now we need to take a look at the structure of the file
head(uwin_sites)
uwin_bbox <- make_bbox(lon = Long, lat = Lat, data = uwin_sites) # create bounding box for uwin
uwin_bbox # looks good but now we need to visualize the points

# now we need our unique API key for the uwin ggmap
ggmap::get_map(location = uwin_bbox, source = "google", maptype = "hybrid") %>% ggmap()

# lets take a look at the map quickly
ggmap(uwin_big)

# now that our bounding area has been declared we can visualize/plot the study area
uwin_map <- ggmap(uwin_big) +
  geom_point(data = uwin_sites, mapping = aes(x = Long, y = Lat, color = Zone))
  print(uwin_map + ggtitle("East Bay UWIN Camera Monitoring Sites")) # color shows up now! Probably because the zones are character values
```

## Loading UWIN sites onto sf map object and other shapefiles ##
```{r loading and visualizing UWIN sites and other landscape elements}
# try to create shapefile or sf object of the uwin sites in the East Bay, I need simple features geometry column in the data
uwin_sf <- st_read("~/Desktop/Meso_Study/eb_shapefiles/uwineastbay/UWIN_East_Bay.shp")
st_geometry_type(uwin_sf) # we need to view the geometric type for the shapefile, they are all points
# now we look at the CRS for the shapefile we have
st_crs(uwin_sf) # WGS84 or World Geodetic system 1984 which is concordant with California, NAD83 might be better?
# now we can find the extent of our points to understand their bounding area
st_bbox(uwin_sf) # bounding box looks good so now we can move forward

# Let's try to visualize the points we have
ggplot() +
  geom_sf(data = uwin_sf, size = 1.5, color = "darkgreen", fill = NA) +
  ggtitle("East Bay Uwin Points") +
  coord_sf()
# we also need to upload shapefiles for our study area to layer over more details, load in the east bay outline
eb_outline <- st_read("~/Desktop/Meso_Study/eb_shapefiles/Bay_Area_Counties/bay_area_counties.shp")
st_crs(eb_outline) # our reference system looks good and is correlative to California, WGS 84
# now lets subset for the counties we are interested in removing the others we dont want
eb_outline <- subset(eb_outline, county == c("Alameda", "Contra Costa"))

# fix the crs for the uwin camer east bay [plot for the study area]
uwin_outline <- st_transform(eb_outline, crs = st_crs(uwin_sf))

# now we need to visualize the county outlines
uwinmap1 <- ggplot() +
  geom_sf(data = uwin_outline, size = 1, color = "black", fill = "lightgray") +
  geom_sf(data = uwin_sf, size = 1.5, color = "forestgreen") +
  ggtitle("UWIN Sites in the East Bay Region") +
  coord_sf(xlim = c(-122.5, -122.15), ylim = c(37.7, 38.05), expand = TRUE) + 
  theme_minimal_grid() # this map looks great! How can we improve it?

 # we need california as the inset map, adjust the crs the layers
uwin_cali <- st_transform(cali_sf, crs = st_crs(uwin_sf))
uwin_counties <- st_transform(counties_sf, crs = st_crs(uwin_sf))

# try to visualize it now
uwinmap2 <- ggplot() + 
    geom_sf(data = uwin_cali, color = NA, lwd = 0.5, fill = "lightgray") +
    geom_sf(data = uwin_counties, color = "black", lwd = 0.5, fill = NA) +
    geom_sf(data = uwin_outline, color = "red", lwd = 0.4 , fill = NA) +
    theme_void() +
    theme(panel.background = element_rect(fill = NULL))

# now we finally draw the inset map for the uwin sites
uwinsetmap <- ggdraw() +
  draw_plot(uwinmap1) +
  draw_plot(uwinmap2, x = 0.24, y = 0.04, width = 0.34, height = 0.34)

# see if the plot looks okay
print(uwinsetmap)

# lets save the sf files for Diego as csv files for him to use
write.csv(uwin_sf, file = "~/Desktop/Meso_Study/ch2aviancats/data/uwin_sf.csv")
write.csv(eb_outline, file = "~/Desktop/Meso_Study/ch2aviancats/data/eb_outline.csv")
ggsave(filename = "uwineastbaymap.jpeg", plot = uwinsetmap, width = 12, height = 8, dpi = 500) # looks good!

# now we need to try and apply some buffers around our uwin sites!

```
# Create buffer zones around uwin sites for covariates ###
```{r creating sf buffer points and extracting covariates}
library(tmap)
p_load(tidycensus, tigris)
cesus_api_key = ("912145d2db1690a9191bb7be7cb0b06c9b3d69")

# first we need to create a buffer around our uwin sites points using the sf package
# buffers should be 500 m to 1500 m for our ranges

uwin.buff <- st_buffer(uwin_sf, 1000) # this sets the buffer radius in meters around our uwin sites
uwin.buff # so the buffer function worked but now we need to visualize it really quick
# we need to adjust the coordinate reference system here


ex1 <- filter(uwin.buff, Site_code == Site_code) # for this var we want to specify all uwin sites, this is for practice
ex2 <- filter(uwin_sf, Site_code == Site_code)

# you need to make sure you define the variable otherwise the rows won't translate to the observations e.g. 1009 obs to 71 obs

tm_shape(eb_outline) +
  tm_polygons() +
  tm_shape(ex1) +
  tm_borders(col = "red") +
  tm_shape(ex2) +
  tm_dots(col = "red") +
  tmap_mode("view") # this gives us an accurate idea of what our sites with buffers look like

# now we need to load in the socioeconomic data for the counties concerning our sites for Alameda and Contra Costa
# first lets looks the variables from ACS
load_variables(2020, dataset = c("dhc"))

census_variables = c("B19013_001") # this only contains median income at the moment

contra_alameda_income <- get_acs(
  geography = "tract",
  variables = c(medincome = "B19013_001"),
  county = c("Contra Costa", "Alameda"),
  state = "CA",
  year = 2022,
  geometry = TRUE,
  output = "wide") # this pulls the 2022 census data for contra costa and alameda looking at median income

contra_alameda_income # now we can take a look at our new sf object, everything is merged together now

# change the CRS for the contra costa and alameda sf object into WGS83, perfect this works!
contra_alameda_income <- st_transform(contra_alameda_income, crs = st_crs(uwin_sf))

plot(contra_alameda_income["medincomeE"]) # this gives us an income estimate for contra costa and alameda

# what are other variables I need to include for socioeconomics? Housing density? Impervious surface area?

# now we layer the uwin sites points and extract info under the buffer radius
# first we do this by intersecting the income sf multipolygons within the radius, and use the right CRS (NAD83/WGS83)

subset.int <- st_intersects(contra_alameda_income, uwin.buff)
subset.int.log = lengths(subset.int) > 0
income.break <- filter(contra_alameda_income, subset.int.log) # now we need to take a look at the sf
income.break # we see we have 139 features instead of 621 from the main sf feature, this could be incorrect though
plot(income.break["medincomeE"]) # the imagery of the map has shifted in relation to the buffer overlap with the areas

# the problem is we need a point to polygon operation if we want to extract the income information and we only have polygons, should I upload zipcode data as GPS points?
# perhaps when I load in the eBird or Avonet data as points I will be able to extract from the buffers and see more clearly
```

# eBird and Avonet
```{r loading in ebird and avonet data from files}
# first you need to obtain an API key from eBird and load it into your workspace
ebird.key <- 'API key here'
# cran release
install.packages("auk")
# Getting started with loading in the data
library(auk)
# set the directory for the location where the data is saved 
ebd_dir <- here("ch2aviancats/ebd_data_2024")

#### Step 1: Cleaning up the dataset ####
#ebd file pathway
ebd_in <- file.path(ebd_dir, "ebd_relJan_2024.txt") # location of our file for ebird data
ebd_clean <- file.path(ebd_dir, "ebd_relJan_2024_clean.txt")
auk_clean(ebd_in, f_out = ebd_clean, remove_text = TRUE) # this spits out the clean text in new file
# Sampling file pathway
ebd_sampling <- file.path(ebd_dir, "ebd_sampling.txt")
ebd_sampling_clean <- file.path(ebd_dir, "ebd_sampling_clean.txt")
auk_clean(ebd_sampling, f_out = ebd_sampling_clean, remove_text = TRUE) # gives us a new sampling event txt file

#### Step 2: Filtering the ebird dataset to specification ####
# define the paths for the ebd and sampling event files
f_in_ebd <- file.path(ebd_dir, "ebd_relJan_2024_clean.txt")
f_in_sampling <- file.path(ebd_dir, "ebd_sampling_clean.txt")
# create an object referencing these files
auk_ebd(file = f_in_ebd, file_sampling = f_in_sampling) # filters have not been set for the object

# define an EBD reference and a set of filters, make sure to include sampling events as well
auk_ebd(ebd_in, ebd_sampling) %>% 
  # now we define our filters, should I include the date?
  auk_bbox(eb_outline) %>% 
  auk_complete()
 # now we check to see if everything was filtered correctly, looks good!

# now we actually have to filter out the data properly and store them in corresponding text files
  f_out_ebd <- file.path(ebd_dir, "ebd_filtered.txt")
  f_out_sampling <- file.path(ebd_dir, "ebd_filtered_sampling.txt") # here out the output files
  
  # define the filters
 ebd_filter <- auk_bbox(eb_outline) %>%
  auk_complete() %>% 
  auk_filter(file = f_out_ebd, file_sampling = f_out_sampling, overwrite = TRUE) # might take some time
 
 ebd_filtered <- auk_ebd(f_in_ebd, f_in_sampling) %>% 
   auk_bbox(bpbox) %>%
   auk_complete() %>% # bounding box filter
   auk_filter(file = f_out_ebd, overwrite = TRUE)
  
### Step 3: Importing the filtered ebird data ####
ebd <- read_ebd(f_out_ebd) # this is my presence-only data and information, original data
presence_ebd <- read_ebd(f_out_ebd) # for the sample data piece
glimpse(ebd) # this gives us a look at the data structure! We have 652k observations!

### Step 4: Pre-processing the dataset ####
glimpse(ebird_taxonomy) # if we want to see the details of the ebird taxonomy list
# we can see what the auk_rollup does to our dataset
auk_rollup(ebd) # its actually still the same since we didn't declare false in the read_ebd
unique(ebd$category) # everything looks good here
# if we want to keep the group checklists and unique categories we declare FALSE in the read_ebd

### Step 5: Now we have to zero-fill our data ####
# now we zero fill our dataset to get presence and absence information
ebd_zf <- auk_zerofill(f_out_ebd, f_out_sampling) # this is presence and absense data
ebd_zf # this should look correct now with the zero fill function, 35k unique checklists for 340 species
# now we merge the two dataframes together using the collapse function for zerofill
ebd_zf_df <- collapse_zerofill(ebd_zf) # this is my complete checklist!!! Extract this! 12 million observations!
# this merges the two dfs, this can be used for distribution modeling, filter this later

### Step 6: mapping the subset of ebird data using the east bay outline ####
# convert to sf object, this is presence only
ebd_sf <- ebd %>% 
  group_by(common_name) %>% 
  st_as_sf( coords = c("longitude", "latitude"), crs = 4326) # EPSG: 4326 is for WGS84!, change to eb_outline 

complete_sf <- ebd_zf_df %>% 
  group_by(scientific_name) %>% 
  st_as_sf( coords = c("longitude", "latitude"), crs = 4326)

# put polygons in same crs
poly_ll <- st_transform(eb_outline, crs = st_crs(ebd_sf)) # this is only if we need to transform our polygon

# identify points in polygon
in_poly <- st_within(ebd_sf, poly_ll, sparse = FALSE)

# although coordinates are longitude/latitude, st_within assumes that they are planar

# subset data frame
ebd_in_eastbay <- ebd[in_poly[, 1], ] # this is our subset dataframe working in the east bay!

# now we can create a simple map looking at EBD observations after spatial subsetting
par(mar = c(0, 0, 0, 0))
plot(eb_outline %>% st_geometry(), col = "grey40", border = NA)
plot(ebd_sf, col = "black", pch = 19, cex = 0.5, add = TRUE)
plot(ebd_sf[in_poly[, 1], ], 
     col = "forestgreen", pch = 19, cex = 0.5, 
     add = TRUE)
legend("top", 
       legend = c("All observations", "After spatial subsetting"), 
       col = c("grey40", "forestgreen"), 
       pch = 19,
       bty = "n",
       ncol = 2)

# lets make a map looking at the observation of different bird species from ebird
par(mar = c(0, 0, 0, 0), bg = "skyblue")
# plot the east bay boundary
plot(eb_outline %>% st_geometry(), col = "grey40", border = "white")
# plot the ebird data of interest
plot(ebd_sf %>% filter(common_name == "California Towhee"),
     col = "red3", pch = 19, cex = 0.75, add = TRUE)
plot(ebd_sf %>% filter(common_name == "Dark-eyed Junco") %>% st_geometry(),
     col = "green3", pch = 19, cex = 0.75, add = TRUE)


```

# Birds & Cats
```{r filtering ebird data to single cat point from ch.1}
# tasks to accomplish for the data extraction of chapter two
# 1. Take 1 km buffer for single cat site from Ch. 1 (done)
# 2. Raster extract/load the Spring migration layer dataset into R (done)
# 3. Get the bird checklists for that specific lat/long relating to the site (done)
# 4. Get the presence-only data for the site (done)
# 5. Send Diego the complete code script and CSV of the data pulled (done)
here::i_am("cat_bird_chapter.Rmd")
setwd('~/Desktop/Meso_Study/ch2aviancats')

# step 1: first we need to take a single shoreline site and create a 1 km buffer for it
kitty_sample <- cat_main_df[1, ]

# now we need to create a buffer zone of 1 km for the kitty sample area, first set the df as a sf object
buff_kitty <- st_as_sf(kitty_sample, coords = c("longitude", "latitude"), 
                       crs = 4326)
# now we set the buffer zone for the single geometry point for 1km
baypoint_buffer <- st_buffer(buff_kitty, 1000)
bpbox <- st_bbox(st_buffer(baypoint_buffer, dist = 1000))

# plot and visualize the baypoint buffer zone
plot(st_geometry(baypoint_buffer), col = "lightblue", main = "Buffer Zone")

# step 2: now we load in the spring migration raster layer
spring_migrate <- raster(here('ch2aviancats/GIS_data/spring_stopover_2500_v9.tif'))

# now we raster extract the information to our camera point
migrate_mean <- raster::extract(spring_migrate, baypoint_buffer, buffer = 1000, fun = mean)
migrate_sd <- raster::extract(spring_migrate, baypoint_buffer, buffer = 1000, fun = sd)

# step 3: now we need to extract the bird data for the specific buffer zone
# first we need to fix the crs for the presence-only filtered data, change it to eb_outline
ebd_sf <- st_transform(ebd_sf, crs = 4326)
# now we need to extract within the buffer zone for the dataset
ebd_presence <- ebd_sf[st_within(ebd_sf, baypoint_buffer, sparse = FALSE), ] # This is correct!
ebd_complete <- complete_sf[st_within(complete_sf, baypoint_buffer, sparse = FALSE), ] # This is correct!

# time to turn the objects to data frames
ebd_presence_df <- as.data.frame(ebd_presence)
ebd_complete_df <- as.data.frame(ebd_complete)

# Step 4: write the information as csv tables to send to Diego for coding troubleshooting
write.csv(ebd_presence_df, "ch2aviancats/R_tables/ebd_presence.csv", row.names = FALSE)
write.csv(ebd_complete_df, "ch2aviancats/R_tables/ebd_complete_checklists.csv", row.names = FALSE)    
```

